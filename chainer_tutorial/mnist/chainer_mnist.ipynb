{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chainerで多層パーセプトロンを作ろう\n",
    "## MNISTデータで手書き文字認識\n",
    "\n",
    "- このファイルは以下のGitHubディレクトリにあるtrain_mnist.pyをipython notebookにペタペタ貼ったものです。\n",
    "https://github.com/pfnet/chainer/tree/master/examples/mnist\n",
    "- [Chainer@GitHub](https://github.com/pfnet/chainer.git)をクローンしてきて、chainer/examples/mnist/の中においても使えます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from chainer import Variable, Chain, optimizers\n",
    "import chainer.functions as F\n",
    "import chainer.links as L"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## データの読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mnist = data.load_mnist_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mnist['data'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_all = mnist['data'].astype(np.float32) / 255\n",
    "y_all = mnist['target'].astype(np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_train, x_test = np.split(x_all, [60000])\n",
    "y_train, y_test = np.split(y_all, [60000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## モデルを定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class MLP(Chain):\n",
    "    def __init__(self):\n",
    "        super(MLP, self).__init__(\n",
    "            l1 = L.Linear(784, 100),\n",
    "            l2 = L.Linear(100, 100),\n",
    "            l3 = L.Linear(100, 10),\n",
    "        )\n",
    "        \n",
    "    def __call__(self, x):\n",
    "        h1 = F.relu(self.l1(x))\n",
    "        h2 = F.relu(self.l2(h1))\n",
    "        y = self.l3(h2)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "損失関数と分類精度の計算をするために、MLP chainの上にclassifier chainを作る。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class MyClassifier(Chain):\n",
    "    \"\"\"\n",
    "    Compute accuracy and loss.\n",
    "    \n",
    "    Returns:\n",
    "        loss\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, predictor):\n",
    "        super(MyClassifier, self).__init__(\n",
    "            predictor=predictor\n",
    "        )\n",
    "    \n",
    "    def __call__(self, x, t):\n",
    "        y = self.predictor(x)\n",
    "        self.loss = F.softmax_cross_entropy(y, t)\n",
    "        self.accuracy = F.accuracy(y, t)\n",
    "        return self.loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "今、定義したMyClassifierクラスと似たクラスが、chainer.links.Classifierに定義されているので、通常はそっちをつかうべし。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = MyClassifier(MLP())\n",
    "#model = L.Classifier(MLP())    # <- 本来ならこっちの方が良い"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "optimizer = optimizers.SGD()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "optimizer.setup(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 書き方１"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batchsize = 100\n",
    "datasize = 60000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for epoch in range(20):\n",
    "    print('epoch %d' % epoch)\n",
    "    indices = np.random.permutation(datasize)\n",
    "    for i in range(0, datasize, batchsize):\n",
    "        x = Variable(x_train[indices[i : i + batchsize]])\n",
    "        t = Variable(y_train[indices[i : i + batchsize]])\n",
    "        \n",
    "        optimizer.update(model, x, t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 書き方２"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batchsize = 100\n",
    "datasize = 60000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for epoch in range(20):\n",
    "    print('epoch %d' % epoch)\n",
    "    \n",
    "    # Compute test/validation error\n",
    "    sum_loss, sum_accuracy = 0, 0\n",
    "    for i in range(0, 10000, batchsize):\n",
    "        x = Variable(x_test[i : i + batchsize])\n",
    "        t = Variable(y_test[i : i + batchsize])\n",
    "        loss = model(x, t)\n",
    "        sum_loss += loss.data * batchsize\n",
    "        sum_accuracy += model.accuracy.data * batchsize\n",
    "\n",
    "    mean_loss = sum_loss / 10000\n",
    "    mean_accuracy = sum_accuracy / 10000\n",
    "\n",
    "    print(\"mean loss: %.5f\\t mean accuracy: %.5f\" % (mean_loss, mean_accuracy))    \n",
    "    \n",
    "    indices = np.random.permutation(datasize)\n",
    "    for i in range(0, datasize, batchsize):\n",
    "        x = Variable(x_train[indices[i : i + batchsize]])\n",
    "        t = Variable(y_train[indices[i : i + batchsize]])\n",
    "        \n",
    "        model.zerograds()\n",
    "        loss = model(x, t)\n",
    "        loss.backward()\n",
    "                \n",
    "        optimizer.update()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
